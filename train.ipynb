{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bc219cbbb14f9fae0e0a746dd94b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython -f -I . -L . -L /home/domin/.local/lib/python3.6/site-packages -I /home/domin/.local/lib/python3.6/site-packages  --cplus \n",
    "\n",
    "from src.Storage cimport Storage\n",
    "from src.MCTS cimport MCTS\n",
    "from src.Model cimport Model\n",
    "from src.ModelRating cimport ModelRating\n",
    "from src.Game cimport Game\n",
    "from gym_watten.envs.watten_env cimport WattenEnv\n",
    "from IPython.display import clear_output\n",
    "from libcpp.vector cimport vector\n",
    "import tensorflow as tf\n",
    "from libcpp cimport bool\n",
    "from libc.stdlib cimport srand\n",
    "from libc.time cimport time\n",
    "import sys\n",
    "\n",
    "cpdef float train(WattenEnv env, Model model, Model trained_model, Model best_model, Storage storage, MCTS mcts, Game game, ModelRating rating, int train_sample_size, object summary_writer, bool is_minimal, object eval_opponents, int offset=0):\n",
    "    cdef int g\n",
    "    cdef vector[float] eval_scores \n",
    "    cdef float rating_value, exploitability, loss    \n",
    "    \n",
    "    srand(time(NULL))\n",
    "    \n",
    "    for g in range(offset, offset + 1000):  \n",
    "        mcts.mcts_generate(env, model, storage)\n",
    "    \n",
    "        loss = trained_model.memorize_storage(storage, train_sample_size == 0, 1, train_sample_size)\n",
    "        clear_output()\n",
    "        \n",
    "        s = tf.Summary(value=[tf.Summary.Value(tag=\"loss\", simple_value=loss)])\n",
    "        summary_writer.add_summary(s, g)\n",
    "        summary_writer.flush()        \n",
    "        \n",
    "        \"\"\"if hasattr(model, 'fit'):\n",
    "            p = np.random.permutation(int(number_of_samples))\n",
    "            if len(p) > BATCH_SIZE * TRAINING_LOOPS:\n",
    "                p = p[:BATCH_SIZE * TRAINING_LOOPS]\n",
    "            train_outputs = []\n",
    "            train_inputs = []\n",
    "            for i in range(len(sample_outputs)):\n",
    "                train_outputs.append(sample_outputs[i][p])\n",
    "            for i in range(len(sample_inputs)):\n",
    "                train_inputs.append(sample_inputs[i][p])\n",
    "\n",
    "            trained_model.fit(train_inputs, train_outputs, epochs=1, batch_size=BATCH_SIZE)   \"\"\"\n",
    "\n",
    "        if g % 1 == 0:\n",
    "            model.copy_weights_from(trained_model)     \n",
    "            #if is_minimal:\n",
    "            #    rating_value = game.compare_given_games(model, best_model, rating)\n",
    "            #else:\n",
    "            rating_value = game.compare_rand_games(model, best_model, 500)\n",
    "\n",
    "            s = tf.Summary(value=[tf.Summary.Value(tag=\"mean_game_length\", simple_value=game.mean_game_length)])\n",
    "            summary_writer.add_summary(s, g)\n",
    "            summary_writer.flush()\n",
    "            \n",
    "            s = tf.Summary(value=[tf.Summary.Value(tag=\"win_rate\", simple_value=rating_value)])\n",
    "            summary_writer.add_summary(s, g)\n",
    "            summary_writer.flush()\n",
    "\n",
    "            print(\"Match: \" + str(rating_value))\n",
    "            sys.stdout.flush()\n",
    "            #print(\"Last scores: \" + str(eval_scores) + \"!\")\n",
    "            if rating_value > 0.52:\n",
    "                best_model.copy_weights_from(model)  \n",
    "                if is_minimal:\n",
    "                    s = tf.Summary(value=[tf.Summary.Value(tag=\"exploitability\", simple_value=rating.calc_exploitability(best_model))])\n",
    "                    summary_writer.add_summary(s, g)\n",
    "                \n",
    "                for key in eval_opponents.keys():\n",
    "                    s = tf.Summary(value=[tf.Summary.Value(tag=\"eval_opponent/\" + key, simple_value=game.compare_rand_games(best_model, eval_opponents[key], 500))])\n",
    "                    summary_writer.add_summary(s, g)\n",
    "                summary_writer.flush()\n",
    "                #exploitability = rating.calc_exploitability(best_model)\n",
    "                #eval_scores.push_back(exploitability)\n",
    "                #print(\"Model score: \" + str(eval_scores.back()) + \"!\")\n",
    "    \n",
    "    if is_minimal:\n",
    "        s = tf.Summary(value=[tf.Summary.Value(tag=\"exploitability\", simple_value=rating.calc_exploitability(best_model))])\n",
    "        summary_writer.add_summary(s, g)\n",
    "        summary_writer.flush()\n",
    "\n",
    "        return rating.calc_exploitability(best_model)\n",
    "    else:\n",
    "        return 0\n",
    "    #plt.plot(eval_scores, label='6x75')\n",
    "    #ax.legend(shadow=True)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(train(env, model, best_model, storage, mcts, game, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter(\"./results/\" + str(\"test\"))\n",
    "train(env, model, best_model, storage, mcts, game, rating, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03214285895228386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.calc_exploitability(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.compare_given_games(model, best_model, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def create_grid_search(variables):\n",
    "    combinations = itertools.product(*variables.values())\n",
    "    labeled_combinations = []\n",
    "    for combination in combinations:\n",
    "        labeled_combinations.append(dict(zip(variables.keys(), combination)))\n",
    "    return labeled_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match: 0.5180000066757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [2:27:35<00:00, 8855.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodes': 75, 'mcts_sims': 40, 'objective_opponent': False, 'storage_size': 10000, 'sample_size': 1000, 'hidden_neurons': 128, 'model': 'Keras', 'minimal': False} 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "variables= {\"episodes\": [75], \"mcts_sims\": [40], \"objective_opponent\": [False], \"storage_size\": [10000], \"sample_size\": [1000], \"hidden_neurons\": [128], \"model\": [\"Keras\"], \"minimal\": [False]}\n",
    "\n",
    "eval_opponent_names = [\"full5Gamev2\"]#\"fullGamev1\"]#\"modelDenseFinal32\", \"modelDenseFinal32v2\", \"modelDenseFinal32v3\"]\n",
    "results = []\n",
    "n = 1\n",
    "best_models = []\n",
    "load_model = \"full5Gamev2\"#\"fullGamev1\"\n",
    "offset = 1300\n",
    "\n",
    "for combination in tqdm(create_grid_search(variables)):\n",
    "    summary_writer = tf.summary.FileWriter(\"./results/full5\" + str(combination) + \" (try 1)\")\n",
    "    score = 0\n",
    "    for i in range(n):\n",
    "        env = WattenEnv(combination[\"minimal\"])\n",
    "        eval_opponents = {}\n",
    "        if combination[\"model\"] is \"Keras\":\n",
    "            model = KerasModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "            best_model = KerasModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "            train_model = KerasModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "            for key in eval_opponent_names:\n",
    "                eval_opponents[key] = KerasModel()\n",
    "                eval_opponents[key].load(key + \".h5\")\n",
    "        else:\n",
    "            model = TinyDnnModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "            best_model = TinyDnnModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "            train_model = TinyDnnModel(combination[\"hidden_neurons\"])#LookUp()\n",
    "        if load_model:\n",
    "            model.load(load_model + \".h5\")\n",
    "        train_model.copy_weights_from(model)\n",
    "        best_model.copy_weights_from(model)\n",
    "        storage = Storage(combination[\"storage_size\"])\n",
    "        mcts = MCTS(combination[\"episodes\"], combination[\"mcts_sims\"], combination[\"objective_opponent\"])\n",
    "        rating = ModelRating(env)\n",
    "        game = Game(env)\n",
    "        score += train(env, model, train_model, best_model, storage, mcts, game, rating, combination[\"sample_size\"], summary_writer, combination[\"minimal\"], eval_opponents, offset)\n",
    "    results.append([combination, score / n])\n",
    "    best_models.append(best_model)\n",
    "for result in results:\n",
    "    print(result[0], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "1 1\n",
      "2 8\n",
      "3 13\n",
      "4 9\n",
      "5 20\n",
      "6 10\n",
      "7 17\n",
      "8 1\n",
      "9 1\n",
      "10 11\n",
      "11 10\n",
      "12 11\n",
      "13 19\n",
      "14 12\n",
      "15 19\n",
      "16 0\n",
      "17 5\n",
      "18 12\n",
      "19 17\n",
      "20 12\n",
      "21 21\n",
      "22 6\n",
      "23 23\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_models)):\n",
    "    wins = 0\n",
    "    for j in range(len(best_models)):\n",
    "        if game.compare_given_games(best_models[i], best_models[j], rating) > 0.5:\n",
    "            wins += 1\n",
    "    print(i, wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -f -I . -L . -L /home/domin/.local/lib/python3.6/site-packages -I /home/domin/.local/lib/python3.6/site-packages  --cplus \n",
    "\n",
    "from src.KerasModel cimport KerasModel\n",
    "\n",
    "cpdef void save(KerasModel m):\n",
    "    m.model.save('full5Gamev3.h5')\n",
    "    \n",
    "cpdef void load(KerasModel m):\n",
    "    m.model.load_weights('full5Gamev3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(best_models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_model = KerasModel()\n",
    "load(prev_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4968999922275543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.compare_rand_games(prev_model, best_models[-1], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -f -I . -L . -L /home/domin/.local/lib/python3.6/site-packages -I /home/domin/.local/lib/python3.6/site-packages  --cplus \n",
    "\n",
    "from src.MCTS cimport MCTS, Storage, MCTSState\n",
    "from src.LookUp cimport LookUp, ModelOutput\n",
    "from src.ModelRating cimport ModelRating\n",
    "from src.Game cimport Game\n",
    "from gym_watten.envs.watten_env cimport WattenEnv, Observation\n",
    "from IPython.display import clear_output\n",
    "from libcpp.vector cimport vector\n",
    "\n",
    "cpdef void show_flaws(WattenEnv env, LookUp model, LookUp better_model, ModelRating rating, int start=0):\n",
    "    cdef Observation obs\n",
    "    cdef ModelOutput output, better_output\n",
    "    cdef int step, better_step\n",
    "    \n",
    "    for g in range(start, rating.eval_games.size()):  \n",
    "        env.reset()\n",
    "        env.set_state(&rating.eval_games[g])\n",
    "        env.regenerate_obs(&obs)\n",
    "    \n",
    "        model.predict_single(&obs, &output)\n",
    "        step = model.valid_step(output.p, &env.players[env.current_player].hand_cards)\n",
    "        \n",
    "        better_model.predict_single(&obs, &better_output)\n",
    "        better_step = better_model.valid_step(better_output.p, &env.players[env.current_player].hand_cards)\n",
    "        \n",
    "        if better_step != step:\n",
    "            env.render('human')\n",
    "            print(g, step, better_step, output.p, better_output.p)\n",
    "            break\n",
    "            \n",
    "cpdef void analyse(WattenEnv env, LookUp model, MCTS mcts, ModelRating rating, int game_id, draw=True):\n",
    "    env.reset()\n",
    "    env.set_state(&rating.eval_games[game_id])\n",
    "    #env.step(0)\n",
    "    #env.step(4)\n",
    "    #env.step(2)\n",
    "    #env.step(1)\n",
    "    env.render('human')\n",
    "    #print(env.is_done())\n",
    "    mcts.objective_opponent = True\n",
    "    \n",
    "    cdef MCTSState root = mcts.create_root_state(env)\n",
    "    cdef vector[float] p\n",
    "    mcts.mcts_game_step(env, &root, model, &p, 40)\n",
    "    print(p)\n",
    "    \n",
    "    if draw:\n",
    "        mcts.draw_tree(&root, 6)\n",
    "\n",
    "cpdef void run(WattenEnv env, LookUp model, ModelRating rating, int game_id):\n",
    "    cdef Observation obs\n",
    "    cdef ModelOutput output\n",
    "    \n",
    "    env.reset()\n",
    "    env.set_state(&rating.eval_games[game_id])\n",
    "    env.regenerate_obs(&obs)\n",
    "    \n",
    "    model.predict_single(&obs, &output)\n",
    "    print(output.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 3 2 [0.30431854724884033, 0.0, 0.28242039680480957, 0.41326066851615906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] [0.302650511264801, 0.0, 0.41321861743927, 0.28413063287734985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "show_flaws(env, best_models[10], best_models[11], rating, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42824968695640564, 0.32129472494125366, 0.2504556179046631]\n",
      "[0.31789714097976685, 0.37508949637413025, 0.3070133626461029]\n",
      "[0.4029049277305603, 0.2813130021095276, 0.3157820701599121]\n",
      "[0.4055160582065582, 0.3133985996246338, 0.281085342168808]\n",
      "[0.3218088448047638, 0.3863930106163025, 0.29179811477661133]\n",
      "[0.40328505635261536, 0.25039905309677124, 0.3463159203529358]\n",
      "[0.40066438913345337, 0.16118615865707397, 0.43814942240715027]\n",
      "[0.4009774327278137, 0.16110198199748993, 0.43792060017585754]\n",
      "[0.24658171832561493, 0.2084484100341797, 0.5449698567390442]\n",
      "[0.22409316897392273, 0.21404504776000977, 0.5618617534637451]\n"
     ]
    }
   ],
   "source": [
    "for i in range(60, 70):\n",
    "    analyse(env, best_models[2], mcts, rating, i, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2822434902191162, 0.4731760025024414, 0.24458058178424835]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a737ef0f2eea46978bea25c27785e7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FigureCanvasNbAgg</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyse(env, best_models[2], mcts, rating, 61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2860535979270935, 0.0, 0.3563016653060913, 0.35764503479003906, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "run(env, best_models[7], rating, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WattenEnv()\n",
    "model = LookUp()\n",
    "best_model = LookUp()\n",
    "storage = Storage()\n",
    "mcts = MCTS()\n",
    "rating = ModelRating(env)\n",
    "game = Game(env)\n",
    "\n",
    "mcts.mcts_generate(env, model, storage)\n",
    "model.memorize_storage(storage)\n",
    "game.compare_given_games(model, best_model, rating)\n",
    "rating.calc_exploitability(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'game' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7f934aafac6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_given_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'game' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(game.compare_given_games(best_models[0], best_models[i], rating, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06607142835855484"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.calc_exploitability(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.020369 s\n",
       "File: src/Game.pyx\n",
       "Function: match at line 16\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    16                                               cpdef int match(self, LookUp agent1, LookUp agent2, bool render=False, bool reset=True):\n",
       "    17                                                   cdef Observation obs\n",
       "    18                                                   cdef ModelOutput output\n",
       "    19                                                   cdef int a\n",
       "    20      1120        696.0      0.6      3.4          if reset:\n",
       "    21                                                       self.env.reset(&obs)\n",
       "    22                                                   else:\n",
       "    23      1120        623.0      0.6      3.1              self.env.regenerate_obs(&obs)\n",
       "    24                                           \n",
       "    25      1120        560.0      0.5      2.7          while not self.env.is_done():\n",
       "    26      4720       2263.0      0.5     11.1              if self.env.current_player == 0:\n",
       "    27      2360       3927.0      1.7     19.3                  agent1.predict_single(&obs, &output)\n",
       "    28      2360       1308.0      0.6      6.4                  a = agent1.valid_step(output.p, &self.env.players[self.env.current_player].hand_cards)\n",
       "    29                                                       else:\n",
       "    30      2360       4001.0      1.7     19.6                  agent2.predict_single(&obs, &output)\n",
       "    31      2360       1274.0      0.5      6.3                  a = agent2.valid_step(output.p, &self.env.players[self.env.current_player].hand_cards)\n",
       "    32                                           \n",
       "    33      4720       2872.0      0.6     14.1              self.env.step(a, &obs)\n",
       "    34                                           \n",
       "    35      4720       2306.0      0.5     11.3              if render:\n",
       "    36                                                           self.env.render('human')\n",
       "    37                                                           sleep(2)\n",
       "    38                                                      # if env.lastTrick  is not None:\n",
       "    39                                                       #    break\n",
       "    40                                           \n",
       "    41      1120        539.0      0.5      2.6          return self.env.last_winner\n",
       "    42                                           \n",
       "    43                                               \"\"\"cdef float compare(self, LookUp agent1, LookUp agent2):\n",
       "    44                                                   cdef vector[LookUp] agents\n",
       "    45                                                   agents.push_back(agent1)\n",
       "    46                                                   agents.push_back(agent2)\n",
       "    47                                                   first_player_wins = 0\n",
       "    48                                           \n",
       "    49                                                   for i in range(10000):\n",
       "    50                                                       start_player = rand() % 2\n",
       "    51                                                       winner = self.match([agents[start_player], agents[1 - start_player]])\n",
       "    52                                                       first_player_wins += ((winner == 0) == (start_player == 0))\n",
       "    53                                                       #print(start_player, winner)\n",
       "    54                                           \n",
       "    55                                                   return first_player_wins / 10000\"\"\"\n",
       "    56                                           \n",
       "    57                                               cpdef float compare_given_games(self, LookUp agent1, LookUp agent2, ModelRating rating):\n",
       "    58                                                   cdef int i, first_player_wins, winner, start_player\n",
       "    59                                                   first_player_wins = 0\n",
       "    60                                           \n",
       "    61                                                   for i in range(rating.eval_games.size()):\n",
       "    62                                                       for start_player in range(2):\n",
       "    63                                                           self.env.set_state(&rating.eval_games[i])\n",
       "    64                                                           self.env.current_player = start_player\n",
       "    65                                                           winner = self.match(agent1, agent2, render=False, reset=False)\n",
       "    66                                                           first_player_wins += (winner == 0)\n",
       "    67                                           \n",
       "    68                                                   return <float>first_player_wins / (rating.eval_games.size() * 2)\n",
       "    69                                           \n",
       "    70                                               def test(self):\n",
       "    71                                                   pass"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f game.match game.compare_given_games(model, best_model, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar 24 00:38:45 2018    Profile.prof\n",
      "\n",
      "         4 function calls in 0.007 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.007    0.007 {built-in method builtins.exec}\n",
      "        1    0.007    0.007    0.007    0.007 {method 'compare_given_games' of 'src.Game.Game' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.007    0.007 <string>:1(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f680c15bc88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pstats, cProfile\n",
    "\n",
    "cProfile.runctx(\"game.compare_given_games(model, best_model, rating)\", globals(), locals(), \"Profile.prof\")\n",
    "\n",
    "s = pstats.Stats(\"Profile.prof\")\n",
    "s.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/line_profiler.py:321: UserWarning: Could not extract a code object for the object 'mcts.mcts_sample'\n",
      "  profile = LineProfiler(*funcs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f70d8ba2d533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lprun'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-f \"mcts.mcts_sample\" train(env, model, storage, mcts)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2095\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2096\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-125>\u001b[0m in \u001b[0;36mlprun\u001b[0;34m(self, parameter_s)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/line_profiler.py\u001b[0m in \u001b[0;36mlprun\u001b[0;34m(self, parameter_s)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                 \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/line_profiler.py\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mexec_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "%lprun -f \"mcts.mcts_sample\" train(env, model, storage, mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(trained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690327380952381"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(models[1], eval_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02589285714285713]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_outputs[1][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5410714285714285"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_given_games(model, first_model, eval_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-aa729d99c6ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict_single([train_inputs[0][next_index - 2], train_inputs[1][next_index - 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.258651  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.27687292, 0.        , 0.        , 0.        ,\n",
       "       0.46447608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs[0][next_index - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs[0][next_index - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_value(test_model.optimizer.lr, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37764/37764 [==============================] - 1s 27us/step - loss: 0.6618 - dense_14_loss: 2.8052e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5164 - dense_15_acc: 0.4518\n",
      "Epoch 2/10\n",
      "37764/37764 [==============================] - 1s 24us/step - loss: 0.6619 - dense_14_loss: 2.7928e-04 - dense_15_loss: 0.6616 - dense_14_acc: 0.5180 - dense_15_acc: 0.4519\n",
      "Epoch 3/10\n",
      "37764/37764 [==============================] - 1s 24us/step - loss: 0.6618 - dense_14_loss: 2.7612e-04 - dense_15_loss: 0.6616 - dense_14_acc: 0.5203 - dense_15_acc: 0.4518\n",
      "Epoch 4/10\n",
      "37764/37764 [==============================] - 1s 24us/step - loss: 0.6618 - dense_14_loss: 2.7579e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5171 - dense_15_acc: 0.4513\n",
      "Epoch 5/10\n",
      "37764/37764 [==============================] - 1s 25us/step - loss: 0.6618 - dense_14_loss: 2.7352e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5153 - dense_15_acc: 0.4513\n",
      "Epoch 6/10\n",
      "37764/37764 [==============================] - 1s 26us/step - loss: 0.6618 - dense_14_loss: 2.7305e-04 - dense_15_loss: 0.6616 - dense_14_acc: 0.5205 - dense_15_acc: 0.4518\n",
      "Epoch 7/10\n",
      "37764/37764 [==============================] - 1s 25us/step - loss: 0.6618 - dense_14_loss: 2.7032e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5186 - dense_15_acc: 0.4522\n",
      "Epoch 8/10\n",
      "37764/37764 [==============================] - 1s 27us/step - loss: 0.6618 - dense_14_loss: 2.6888e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5183 - dense_15_acc: 0.4515\n",
      "Epoch 9/10\n",
      "37764/37764 [==============================] - 1s 27us/step - loss: 0.6617 - dense_14_loss: 2.6399e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5184 - dense_15_acc: 0.4523\n",
      "Epoch 10/10\n",
      "37764/37764 [==============================] - 1s 27us/step - loss: 0.6618 - dense_14_loss: 2.6460e-04 - dense_15_loss: 0.6615 - dense_14_acc: 0.5190 - dense_15_acc: 0.4518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44962f95f8>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit([sample_inputs[0][:number_of_samples], sample_inputs[1][:number_of_samples]], [sample_outputs[0][:number_of_samples], sample_outputs[1][:number_of_samples]], epochs=10, batch_size=BATCH_SIZE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.0053017 , 0.0045248 , 0.00548624, 0.00582314, 0.0070843 ,\n",
       "        0.00583717, 0.00645116, 0.00290738, 0.00513383, 0.0056636 ,\n",
       "        0.331735  , 0.00607965, 0.0053452 , 0.00601907, 0.33392397,\n",
       "        0.0070668 , 0.00368037, 0.01111693, 0.00290891, 0.00334794,\n",
       "        0.00270144, 0.00335149, 0.00295761, 0.00356095, 0.00431994,\n",
       "        0.00539099, 0.00628497, 0.00557014, 0.3452927 , 0.00649954,\n",
       "        0.00652416, 0.00288056], dtype=float32),\n",
       " array([-0.81022185], dtype=float32)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.predict_single([sample_inputs[0][5], sample_inputs[1][5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37764"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_outputs[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23038077, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15442885, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.23038077,\n",
       "       0.        , 0.        , 0.        , 0.23038077, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.15442885, 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_outputs[0][10638]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.127"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(model, eval_cache_input, eval_cache_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743247537337147"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = test_model.predict([sample_inputs[0][:number_of_samples], sample_inputs[1][:number_of_samples]])[0]\n",
    "a = np.argmax(model_output, axis=-1)\n",
    "k = np.equal(np.take(sample_outputs[0][:number_of_samples], np.argmax(sample_outputs[0][:number_of_samples], axis=-1)), np.take(sample_outputs[0][:number_of_samples], a)).sum()\n",
    "k / number_of_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LookUp' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-51cb5e688689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelDense3.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LookUp' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model.save('modelDense3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('modelDense2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-545214702627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_given_games\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_games\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "compare_given_games(best_model, models[2], eval_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_nn_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.690327380952381"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(best_model, eval_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 4, 8, 2)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 68)           0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         70656       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 68)           0           flatten_1[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           32800       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            69          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 103,525\n",
      "Trainable params: 103,525\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
